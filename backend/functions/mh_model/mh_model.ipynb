{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mental health detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/venessa/Desktop/SchemesSG_v3/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from transformers import pipeline, Trainer, TrainingArguments, BertTokenizer, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the fine-tuned models from here into the same folder:\n",
    "https://drive.google.com/drive/folders/1XhWWajqF6tI_9wfRp-kI18HQcgObxTez?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labelled data\n",
    "df = pd.read_csv('data_labelled.csv')\n",
    "\n",
    "# Train-test split\n",
    "X = df['query']\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluator function for results\n",
    "\n",
    "def evaluate_results(y, y_pred):\n",
    "    print(classification_report(y, y_pred))\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y, y_pred))\n",
    "    print('Accuracy:', accuracy_score(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of 3 fine-tuned models on test dataset\n",
    "\n",
    "Model #1 performs the best in terms of overall accuracy and F1-score, especially for positive examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91       189\n",
      "           1       0.60      0.30      0.40        40\n",
      "\n",
      "    accuracy                           0.84       229\n",
      "   macro avg       0.73      0.63      0.65       229\n",
      "weighted avg       0.82      0.84      0.82       229\n",
      "\n",
      "Confusion Matrix:\n",
      "[[181   8]\n",
      " [ 28  12]]\n",
      "Accuracy: 0.8427947598253275\n"
     ]
    }
   ],
   "source": [
    "# predict using model 1\n",
    "classifier = pipeline('text-classification', model='ardavey/bert-large-depression-classification-model')\n",
    "y_pred = classifier(X_test.tolist())\n",
    "y_pred = [1 if pred['label'] == 'LABEL_1' else 0 for pred in y_pred]\n",
    "evaluate_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/venessa/Desktop/SchemesSG_v3/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.90       189\n",
      "           1       0.00      0.00      0.00        40\n",
      "\n",
      "    accuracy                           0.83       229\n",
      "   macro avg       0.41      0.50      0.45       229\n",
      "weighted avg       0.68      0.83      0.75       229\n",
      "\n",
      "Confusion Matrix:\n",
      "[[189   0]\n",
      " [ 40   0]]\n",
      "Accuracy: 0.8253275109170306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/venessa/Desktop/SchemesSG_v3/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/venessa/Desktop/SchemesSG_v3/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/venessa/Desktop/SchemesSG_v3/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# predict using model 2\n",
    "classifier = pipeline(\"text-classification\", model=\"rafalposwiata/deproberta-large-depression\")\n",
    "y_pred = classifier(X_test.tolist())\n",
    "y_pred = [1 if pred['label'] == 'LABEL_1' else 0 for pred in y_pred]\n",
    "evaluate_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.78       189\n",
      "           1       0.04      0.05      0.05        40\n",
      "\n",
      "    accuracy                           0.64       229\n",
      "   macro avg       0.42      0.41      0.41       229\n",
      "weighted avg       0.66      0.64      0.65       229\n",
      "\n",
      "Confusion Matrix:\n",
      "[[144  45]\n",
      " [ 38   2]]\n",
      "Accuracy: 0.6375545851528385\n"
     ]
    }
   ],
   "source": [
    "# predict using model 3\n",
    "classifier = pipeline(\"text-classification\", model=\"poudel/Depression_and_Non-Depression_Classifier\")     \n",
    "y_pred = classifier(X_test.tolist())\n",
    "y_pred = [1 if pred['label'] == 'LABEL_1' else 0 for pred in y_pred]\n",
    "evaluate_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further fine-tuning of model\n",
    "\n",
    "Fine-tuning can be done in two ways: updating all model parameters (without freezing) or only updating the classification head (with freezing).\n",
    "\n",
    "- **Without Freezing**: The entire BERT model, including the pre-trained layers, is updated during fine-tuning. This enables the model to adapt its internal representations to the specific dataset. However, it requires more computational resources and has a higher risk of overfitting when the dataset is small.\n",
    "\n",
    "- **With Freezing**: The pre-trained BERT layers are kept fixed, and only the classification head (the top layer) is updated during fine-tuning. This approach reduces computational cost, speeds up training, and lowers the risk of overfitting, as fewer parameters are updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data using BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['query'], padding=True, truncation=True)\n",
    "\n",
    "# Create a Dataset object for Hugging Face\n",
    "train_dataset = Dataset.from_pandas(pd.DataFrame({'query': X_train, 'label': y_train}))\n",
    "test_dataset = Dataset.from_pandas(pd.DataFrame({'query': X_test, 'label': y_test}))\n",
    "\n",
    "# Tokenize the datasets\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/venessa/Desktop/SchemesSG_v3/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 912/912 [00:00<00:00, 10685.17 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 229/229 [00:00<00:00, 12454.56 examples/s]\n",
      "/Users/venessa/Desktop/SchemesSG_v3/.venv/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "  3%|â–Ž         | 10/342 [00:08<02:31,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7609, 'grad_norm': 6.425285339355469, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 20/342 [00:12<02:08,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3403, 'grad_norm': 0.18243823945522308, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|â–‰         | 30/342 [00:16<02:04,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7445, 'grad_norm': 39.150054931640625, 'learning_rate': 3e-06, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–        | 40/342 [00:20<02:00,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6663, 'grad_norm': 1.9011421203613281, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–        | 50/342 [00:24<01:58,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5783, 'grad_norm': 22.562572479248047, 'learning_rate': 5e-06, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|â–ˆâ–Š        | 60/342 [00:28<01:53,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9903, 'grad_norm': 3.9119348526000977, 'learning_rate': 6e-06, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 70/342 [00:32<01:48,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3262, 'grad_norm': 1.0442955493927002, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|â–ˆâ–ˆâ–Ž       | 80/342 [00:36<01:44,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7036, 'grad_norm': 3.3780641555786133, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|â–ˆâ–ˆâ–‹       | 90/342 [00:40<01:40,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3559, 'grad_norm': 1.6936789751052856, 'learning_rate': 9e-06, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|â–ˆâ–ˆâ–‰       | 100/342 [00:44<01:37,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3384, 'grad_norm': 2.4014511108398438, 'learning_rate': 1e-05, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 110/342 [00:48<01:33,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4976, 'grad_norm': 5.236722946166992, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 114/342 [00:51<01:31,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3900357782840729, 'eval_accuracy': 0.8646288209606987, 'eval_runtime': 1.6905, 'eval_samples_per_second': 135.465, 'eval_steps_per_second': 8.873, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 120/342 [00:53<01:48,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4302, 'grad_norm': 4.51938009262085, 'learning_rate': 1.2e-05, 'epoch': 1.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 130/342 [00:57<01:25,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3325, 'grad_norm': 4.009026050567627, 'learning_rate': 1.3000000000000001e-05, 'epoch': 1.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 140/342 [01:01<01:20,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.456, 'grad_norm': 89.54991912841797, 'learning_rate': 1.4000000000000001e-05, 'epoch': 1.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 150/342 [01:05<01:16,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4523, 'grad_norm': 21.014942169189453, 'learning_rate': 1.5e-05, 'epoch': 1.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 160/342 [01:09<01:13,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4166, 'grad_norm': 5.624212265014648, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 170/342 [01:13<01:08,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2619, 'grad_norm': 25.714555740356445, 'learning_rate': 1.7000000000000003e-05, 'epoch': 1.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 180/342 [01:17<01:04,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3567, 'grad_norm': 6.1997857093811035, 'learning_rate': 1.8e-05, 'epoch': 1.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 190/342 [01:21<01:00,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3435, 'grad_norm': 21.957216262817383, 'learning_rate': 1.9e-05, 'epoch': 1.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 200/342 [01:25<00:56,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2951, 'grad_norm': 57.03313064575195, 'learning_rate': 2e-05, 'epoch': 1.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 210/342 [01:29<00:53,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3695, 'grad_norm': 8.164864540100098, 'learning_rate': 2.1e-05, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 220/342 [01:33<00:48,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2129, 'grad_norm': 17.56536293029785, 'learning_rate': 2.2000000000000003e-05, 'epoch': 1.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 228/342 [01:38<00:45,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.33560559153556824, 'eval_accuracy': 0.9082969432314411, 'eval_runtime': 1.1607, 'eval_samples_per_second': 197.298, 'eval_steps_per_second': 12.923, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 230/342 [01:39<01:11,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1022, 'grad_norm': 24.8367862701416, 'learning_rate': 2.3000000000000003e-05, 'epoch': 2.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 240/342 [01:43<00:41,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4272, 'grad_norm': 0.22573645412921906, 'learning_rate': 2.4e-05, 'epoch': 2.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 250/342 [01:47<00:37,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1544, 'grad_norm': 0.6583957672119141, 'learning_rate': 2.5e-05, 'epoch': 2.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 260/342 [01:51<00:34,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3294, 'grad_norm': 0.4154665768146515, 'learning_rate': 2.6000000000000002e-05, 'epoch': 2.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 270/342 [01:55<00:29,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0729, 'grad_norm': 0.20394989848136902, 'learning_rate': 2.7000000000000002e-05, 'epoch': 2.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 280/342 [01:59<00:25,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2517, 'grad_norm': 58.30704879760742, 'learning_rate': 2.8000000000000003e-05, 'epoch': 2.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 290/342 [02:03<00:21,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4097, 'grad_norm': 24.86795997619629, 'learning_rate': 2.9e-05, 'epoch': 2.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 300/342 [02:07<00:17,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5156, 'grad_norm': 5.22513484954834, 'learning_rate': 3e-05, 'epoch': 2.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 310/342 [02:11<00:13,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0643, 'grad_norm': 0.19349312782287598, 'learning_rate': 3.1e-05, 'epoch': 2.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 320/342 [02:15<00:08,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1909, 'grad_norm': 0.09790951758623123, 'learning_rate': 3.2000000000000005e-05, 'epoch': 2.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 330/342 [02:19<00:04,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0452, 'grad_norm': 0.0631057471036911, 'learning_rate': 3.3e-05, 'epoch': 2.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 340/342 [02:23<00:00,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1818, 'grad_norm': 0.05640042573213577, 'learning_rate': 3.4000000000000007e-05, 'epoch': 2.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 342/342 [02:27<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36817458271980286, 'eval_accuracy': 0.9344978165938864, 'eval_runtime': 1.1718, 'eval_samples_per_second': 195.432, 'eval_steps_per_second': 12.801, 'epoch': 3.0}\n",
      "{'train_runtime': 147.9297, 'train_samples_per_second': 18.495, 'train_steps_per_second': 2.312, 'train_loss': 0.37939673118097217, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 14.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       189\n",
      "           1       0.90      0.70      0.79        40\n",
      "\n",
      "    accuracy                           0.93       229\n",
      "   macro avg       0.92      0.84      0.87       229\n",
      "weighted avg       0.93      0.93      0.93       229\n",
      "\n",
      "Confusion Matrix:\n",
      "[[186   3]\n",
      " [ 12  28]]\n",
      "Accuracy: 0.9344978165938864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_model/tokenizer_config.json',\n",
       " './fine_tuned_model/special_tokens_map.json',\n",
       " './fine_tuned_model/vocab.txt',\n",
       " './fine_tuned_model/added_tokens.json')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tuning BERT model without freezing\n",
    "\n",
    "# Load the pre-trained BERT model\n",
    "model = BertForSequenceClassification.from_pretrained('ardavey/bert-large-depression-classification-model', num_labels=2)\n",
    "\n",
    "# Set up the Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='.',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=lambda p: {'accuracy': accuracy_score(p.predictions.argmax(axis=-1), p.label_ids)}\n",
    ")\n",
    "\n",
    "#  Fine-tune the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model after fine-tuning\n",
    "predictions, labels, metrics = trainer.predict(test_dataset)\n",
    "\n",
    "# Convert predictions to binary labels\n",
    "predicted_labels = predictions.argmax(axis=-1)\n",
    "\n",
    "# Step 8: Print evaluation metrics\n",
    "evaluate_results(y_test, predicted_labels)\n",
    "\n",
    "# Save the fine-tuned model for future use\n",
    "model.save_pretrained('./fine_tuned_model')\n",
    "tokenizer.save_pretrained('./fine_tuned_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 912/912 [00:00<00:00, 11523.02 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 229/229 [00:00<00:00, 12055.17 examples/s]\n",
      "  3%|â–Ž         | 11/342 [00:01<00:31, 10.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7636, 'grad_norm': 6.137767791748047, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 21/342 [00:02<00:30, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3415, 'grad_norm': 0.14921130239963531, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|â–‰         | 31/342 [00:02<00:29, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7855, 'grad_norm': 4.9290313720703125, 'learning_rate': 3e-06, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–        | 41/342 [00:03<00:28, 10.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6872, 'grad_norm': 0.920016884803772, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–        | 51/342 [00:04<00:27, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7853, 'grad_norm': 8.969738006591797, 'learning_rate': 5e-06, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|â–ˆâ–Š        | 61/342 [00:05<00:26, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2037, 'grad_norm': 6.042139053344727, 'learning_rate': 6e-06, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|â–ˆâ–ˆ        | 71/342 [00:06<00:25, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4526, 'grad_norm': 0.2766213119029999, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|â–ˆâ–ˆâ–Ž       | 81/342 [00:07<00:24, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0527, 'grad_norm': 2.830249547958374, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|â–ˆâ–ˆâ–‹       | 91/342 [00:08<00:23, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5532, 'grad_norm': 2.85831356048584, 'learning_rate': 9e-06, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–‰       | 101/342 [00:09<00:23, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5597, 'grad_norm': 2.9287912845611572, 'learning_rate': 1e-05, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 111/342 [00:10<00:22, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7923, 'grad_norm': 6.509459018707275, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 113/342 [00:10<00:21, 10.46it/s]\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 114/342 [00:12<00:21, 10.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7382754683494568, 'eval_accuracy': 0.8427947598253275, 'eval_runtime': 1.0918, 'eval_samples_per_second': 209.75, 'eval_steps_per_second': 13.739, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 121/342 [00:13<00:40,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8073, 'grad_norm': 2.4183616638183594, 'learning_rate': 1.2e-05, 'epoch': 1.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 131/342 [00:14<00:23,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4998, 'grad_norm': 0.6423311829566956, 'learning_rate': 1.3000000000000001e-05, 'epoch': 1.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 141/342 [00:15<00:19, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7186, 'grad_norm': 7.248355388641357, 'learning_rate': 1.4000000000000001e-05, 'epoch': 1.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 151/342 [00:16<00:18, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6649, 'grad_norm': 6.666010856628418, 'learning_rate': 1.5e-05, 'epoch': 1.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 161/342 [00:17<00:17, 10.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6315, 'grad_norm': 2.5622169971466064, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 171/342 [00:18<00:16, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4871, 'grad_norm': 8.15990161895752, 'learning_rate': 1.7000000000000003e-05, 'epoch': 1.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 181/342 [00:19<00:15, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6647, 'grad_norm': 0.35049477219581604, 'learning_rate': 1.8e-05, 'epoch': 1.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 191/342 [00:20<00:14, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5825, 'grad_norm': 9.48819637298584, 'learning_rate': 1.9e-05, 'epoch': 1.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 201/342 [00:20<00:13, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.743, 'grad_norm': 0.45881524682044983, 'learning_rate': 2e-05, 'epoch': 1.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 211/342 [00:21<00:12, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7371, 'grad_norm': 5.728250503540039, 'learning_rate': 2.1e-05, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 221/342 [00:22<00:11, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4999, 'grad_norm': 5.40435791015625, 'learning_rate': 2.2000000000000003e-05, 'epoch': 1.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 227/342 [00:23<00:10, 10.49it/s]\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 228/342 [00:24<00:10, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.597592830657959, 'eval_accuracy': 0.8427947598253275, 'eval_runtime': 1.0879, 'eval_samples_per_second': 210.495, 'eval_steps_per_second': 13.788, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 231/342 [00:25<00:28,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2733, 'grad_norm': 3.185177803039551, 'learning_rate': 2.3000000000000003e-05, 'epoch': 2.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 241/342 [00:26<00:12,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.722, 'grad_norm': 7.009829521179199, 'learning_rate': 2.4e-05, 'epoch': 2.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 251/342 [00:27<00:09, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4837, 'grad_norm': 3.236232280731201, 'learning_rate': 2.5e-05, 'epoch': 2.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 261/342 [00:28<00:07, 10.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4624, 'grad_norm': 2.7675082683563232, 'learning_rate': 2.6000000000000002e-05, 'epoch': 2.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 271/342 [00:29<00:06, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3295, 'grad_norm': 0.978152334690094, 'learning_rate': 2.7000000000000002e-05, 'epoch': 2.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 281/342 [00:30<00:05, 10.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3431, 'grad_norm': 2.1640729904174805, 'learning_rate': 2.8000000000000003e-05, 'epoch': 2.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 291/342 [00:31<00:04, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7117, 'grad_norm': 5.430723190307617, 'learning_rate': 2.9e-05, 'epoch': 2.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 301/342 [00:31<00:03, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4116, 'grad_norm': 0.9284413456916809, 'learning_rate': 3e-05, 'epoch': 2.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 311/342 [00:32<00:02, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.638, 'grad_norm': 5.042006492614746, 'learning_rate': 3.1e-05, 'epoch': 2.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 321/342 [00:33<00:02, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3348, 'grad_norm': 2.0180606842041016, 'learning_rate': 3.2000000000000005e-05, 'epoch': 2.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 331/342 [00:34<00:01, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.504, 'grad_norm': 1.9963586330413818, 'learning_rate': 3.3e-05, 'epoch': 2.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 341/342 [00:35<00:00, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5233, 'grad_norm': 2.8907768726348877, 'learning_rate': 3.4000000000000007e-05, 'epoch': 2.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 342/342 [00:37<00:00, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.47875064611434937, 'eval_accuracy': 0.8427947598253275, 'eval_runtime': 1.133, 'eval_samples_per_second': 202.126, 'eval_steps_per_second': 13.24, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 342/342 [00:38<00:00,  8.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 38.6606, 'train_samples_per_second': 70.77, 'train_steps_per_second': 8.846, 'train_loss': 0.6099620074556585, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 14.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91       189\n",
      "           1       0.60      0.30      0.40        40\n",
      "\n",
      "    accuracy                           0.84       229\n",
      "   macro avg       0.73      0.63      0.65       229\n",
      "weighted avg       0.82      0.84      0.82       229\n",
      "\n",
      "Confusion Matrix:\n",
      "[[181   8]\n",
      " [ 28  12]]\n",
      "Accuracy: 0.8427947598253275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_model_freeze/tokenizer_config.json',\n",
       " './fine_tuned_model_freeze/special_tokens_map.json',\n",
       " './fine_tuned_model_freeze/vocab.txt',\n",
       " './fine_tuned_model_freeze/added_tokens.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune model, freezing BERT layers\n",
    "\n",
    "# Load the pre-trained BERT model\n",
    "model = BertForSequenceClassification.from_pretrained('ardavey/bert-large-depression-classification-model', num_labels=2)\n",
    "\n",
    "# Freeze the BERT layers\n",
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Set up the Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='.',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,  \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=lambda p: {'accuracy': accuracy_score(p.predictions.argmax(axis=-1), p.label_ids)}\n",
    ")\n",
    "\n",
    "#  Fine-tune the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model after fine-tuning\n",
    "predictions, labels, metrics = trainer.predict(test_dataset)\n",
    "\n",
    "# Convert predictions to binary labels\n",
    "predicted_labels = predictions.argmax(axis=-1)\n",
    "\n",
    "# Step 8: Print evaluation metrics\n",
    "evaluate_results(y_test, predicted_labels)\n",
    "\n",
    "# Save the fine-tuned model for future use\n",
    "model.save_pretrained('./fine_tuned_model_freeze')\n",
    "tokenizer.save_pretrained('./fine_tuned_model_freeze')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning without freezing led to greater improvements in both overall accuracy and F1 score compared to fine-tuning with freezing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps\n",
    "\n",
    "For next steps we can either:\n",
    "1. Continue to improve the model by exploring more models, synthesizing more data, etc\n",
    "2. Integrate the model with the existing code to enable mental health detection functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "# Test the fine-tuned model\n",
    "\n",
    "classifier = pipeline('text-classification', model='./fine_tuned_model')\n",
    "prediction = classifier('I feel sad and hopeless')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
