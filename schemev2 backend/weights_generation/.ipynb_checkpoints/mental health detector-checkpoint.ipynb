{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>MH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>depress</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>depress</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>sad</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>sad</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>sad</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Text  MH\n",
       "316  depress   1\n",
       "317  depress   1\n",
       "318      sad   1\n",
       "319      sad   1\n",
       "320      sad   1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mh = pd.read_csv('../mentalhealth.csv', encoding='cp1252')\n",
    "df_mh['Text'] = df_mh['Text'].astype(str)\n",
    "df_mh.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "def cleanText(text):\n",
    "    text = BeautifulSoup(text, \"lxml\").text\n",
    "    text = re.sub(r'\\|\\|\\|', r' ', text) \n",
    "    text = re.sub(r'http\\S+', r'<URL>', text)\n",
    "    text = text.lower()\n",
    "    text = text.replace('x', '')\n",
    "    return text\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "def stemSentence(sentence):\n",
    "    token_words=word_tokenize(sentence)\n",
    "    token_words\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(porter.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)\n",
    "\n",
    "df_mh['Text'] = df_mh['Text'].apply(cleanText).apply(stemSentence)\n",
    "df_mh=df_mh[['Text','MH']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>MH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my client need marit counsel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>counsel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>career counsel , youth</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>counsel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>counsel in redhil</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>depress</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>depress</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>sad</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>sad</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>sad</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>321 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Text  MH\n",
       "0    my client need marit counsel    1\n",
       "1                         counsel    1\n",
       "2          career counsel , youth    1\n",
       "3                         counsel    1\n",
       "4               counsel in redhil    1\n",
       "..                             ...  ..\n",
       "316                       depress    1\n",
       "317                       depress    1\n",
       "318                           sad    1\n",
       "319                           sad    1\n",
       "320                           sad    1\n",
       "\n",
       "[321 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_mh, test_size=0.3, random_state=42)\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens\n",
    "train_tagged = train.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['Text']), tags=[r.MH]), axis=1)\n",
    "test_tagged = test.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['Text']), tags=[r.MH]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['my', 'wife', 'bulli', 'me'], tags=[1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check\n",
    "train_tagged.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>MH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>i am an elderli who just left the hospit and h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>elderli mental ill financi assist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>buy a hous</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>my wife bulli me</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>im look for work after covid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>i am a home buyer who need help with mortgag f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>i am a wife of a person with depress and would...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>help me pleas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>co-op</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>burn out</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text  MH\n",
       "206  i am an elderli who just left the hospit and h...   0\n",
       "81                  elderli mental ill financi assist    1\n",
       "147                                        buy a hous    0\n",
       "39                                   my wife bulli me    1\n",
       "222                      im look for work after covid    0\n",
       "..                                                 ...  ..\n",
       "188  i am a home buyer who need help with mortgag f...   0\n",
       "71   i am a wife of a person with depress and would...   1\n",
       "106                                     help me pleas    1\n",
       "270                                             co-op    0\n",
       "102                                          burn out    1\n",
       "\n",
       "[224 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=0, hs=0, min_count=2, sample = 0, workers=cores)\n",
    "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<00:00, 224497.99it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<00:00, 233132.53it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<00:00, 224659.04it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<00:00, 224497.99it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<00:00, 224927.96it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<00:00, 224230.09it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<00:00, 224981.82it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<00:00, 224874.13it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<00:00, 224497.99it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<00:00, 111662.00it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<00:00, 224981.82it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<00:00, 74868.44it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<00:00, 224927.96it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<00:00, 224874.13it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<00:00, 112115.05it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<00:00, 223217.89it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<00:00, 226282.30it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<00:00, 225630.19it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<00:00, 224390.76it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<00:00, 224605.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 451 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.6701030927835051\n",
      "Testing F1 score: 0.6701030927835051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dmm = Doc2Vec(dm=1, dm_mean=1, vector_size=300, window=10, negative=0, min_count=1, workers=5, alpha=0.065, min_alpha=0.065)\n",
    "model_dmm.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<00:00, 221809.33it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<00:00, 221809.33it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<00:00, 220910.67it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<00:00, 220385.45it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<00:00, 221703.23it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<00:00, 220910.67it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<00:00, 221544.26it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<00:00, 221862.42it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<00:00, 221597.22it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<00:00, 221174.23it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<00:00, 221650.21it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<00:00, 221385.52it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<00:00, 221862.42it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<00:00, 223467.02it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<00:00, 111010.92it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<00:00, 222021.84it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 697 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_dmm.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dmm.alpha -= 0.002\n",
    "    model_dmm.min_alpha = model_dmm.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.6105263157894737\n",
      "Testing F1 score: 0.6075166842290131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "y_train, X_train = vec_for_learning(model_dmm, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dmm, test_tagged)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "new_model = ConcatenatedDoc2Vec([model_dbow, model_dmm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.5894736842105263\n",
      "Testing F1 score: 0.5885217391304348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "y_train, X_train = get_vectors(new_model, train_tagged)\n",
    "y_test, X_test = get_vectors(new_model, test_tagged)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03588029, 0.96411971]])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict_proba(X_test[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.6103857e-03, -2.9161328e-03, -4.1409791e-04, -6.4260354e-03,\n",
       "         1.2808194e-03,  3.4070965e-03,  1.7390258e-03, -4.5630243e-03,\n",
       "         1.0000954e-03,  1.4912349e-03,  9.2142262e-04,  3.5733518e-03,\n",
       "        -3.3480150e-03, -4.4166860e-03, -9.1214804e-04,  5.3640013e-03,\n",
       "        -4.7140769e-03, -2.7726034e-03,  4.9596891e-04, -4.4774725e-03,\n",
       "         4.1144770e-03, -3.5437602e-03, -4.6830974e-05, -4.2425273e-03,\n",
       "        -5.2534690e-04, -2.3834542e-03,  1.4799949e-03,  2.9475787e-03,\n",
       "        -3.6627473e-03,  4.8638997e-03,  1.3529626e-03,  1.9870931e-06,\n",
       "         1.0597311e-03, -1.7081578e-03, -4.5323779e-04,  7.6682155e-04,\n",
       "         3.3804262e-03,  5.7552163e-03,  1.2841951e-03,  1.3982989e-03,\n",
       "         9.8019838e-04, -1.3635990e-03,  2.5398917e-03, -2.7097838e-03,\n",
       "         8.1360730e-04,  3.5077156e-03,  2.3070904e-03, -3.4542237e-03,\n",
       "         9.0059591e-05, -3.4422074e-03,  3.1805192e-03, -3.5190992e-03,\n",
       "         1.6805908e-03, -3.1540890e-03,  1.9004911e-03,  3.4608936e-04,\n",
       "         5.5224393e-03, -4.5879376e-03,  5.5250018e-03, -1.4847443e-03,\n",
       "        -2.7026788e-03, -6.0435054e-03,  2.3378755e-03,  2.0707245e-03,\n",
       "        -2.7810622e-03, -2.0824696e-03,  4.6348624e-04,  1.5617630e-03,\n",
       "         1.8638816e-03, -1.5317590e-03,  5.3749606e-03,  3.7231841e-03,\n",
       "         5.5980240e-03,  1.8384343e-03, -3.3244463e-03, -5.6331593e-04,\n",
       "        -2.4838608e-03,  4.5793294e-03, -1.7203679e-03, -6.0346616e-03,\n",
       "         4.0603727e-03, -7.9067604e-04,  6.8340702e-03, -4.1115102e-03,\n",
       "        -1.7697137e-03, -2.4926900e-03,  1.0632665e-03,  4.1360979e-04,\n",
       "         6.0542335e-04,  5.1263557e-03,  1.8737366e-03, -7.6685811e-04,\n",
       "         6.7826314e-03,  1.1862597e-03,  4.5945551e-03, -4.7035622e-03,\n",
       "         2.3996863e-03, -3.4517525e-03, -2.7804235e-03,  8.7339297e-04,\n",
       "         3.3822560e-03,  4.5225904e-03,  2.2755463e-03, -8.7839187e-05,\n",
       "         3.9440575e-03,  3.3801242e-03,  2.4380139e-03, -4.9399845e-03,\n",
       "        -1.0779605e-03, -3.1743562e-03,  1.3343743e-03,  1.0215645e-03,\n",
       "        -3.9733611e-03, -1.7054395e-03, -1.7183716e-03, -2.0527213e-03,\n",
       "         4.2616022e-03, -1.9779075e-03, -1.3756666e-03, -4.2758957e-03,\n",
       "         5.5447978e-04, -2.6491154e-03, -3.0875229e-04,  3.5584662e-03,\n",
       "         3.3383362e-03, -2.2657539e-03,  6.8903319e-05,  7.8926457e-04,\n",
       "         3.0932346e-04, -6.7359651e-04, -4.7626165e-03, -3.0518626e-03,\n",
       "         2.7838661e-03, -5.2691624e-03, -1.7903508e-03, -2.4740784e-03,\n",
       "         2.6518693e-03,  3.3326233e-03,  3.8819923e-04, -5.7594676e-05,\n",
       "         3.4140348e-03, -1.9437268e-03,  2.1113867e-03,  6.9102538e-03,\n",
       "         3.6373641e-03, -3.1639687e-03, -4.5554345e-03,  2.0619880e-03,\n",
       "         3.7771379e-04, -1.5726470e-04, -8.5678982e-04,  4.5539839e-03,\n",
       "        -1.8953427e-03, -1.1646756e-03,  2.5058803e-03,  7.3442579e-04,\n",
       "        -4.1113487e-03,  4.3297969e-04,  8.9494535e-04, -2.8656353e-03,\n",
       "        -4.8539788e-03,  2.8537351e-03, -1.7390314e-03, -1.6593786e-03,\n",
       "        -9.3958795e-04, -4.7809823e-04, -3.0032953e-03, -2.3411484e-03,\n",
       "        -3.7392782e-04,  1.8123594e-03, -4.0957523e-03,  3.4438297e-03,\n",
       "         9.6997514e-04, -1.5038477e-03, -2.0935091e-03, -4.5183077e-03,\n",
       "        -2.7848775e-03,  5.2274298e-03,  2.4071010e-03,  5.7016443e-03,\n",
       "        -7.8858365e-04, -6.4370240e-04,  4.0430119e-03,  5.0233100e-03,\n",
       "         6.3911313e-04,  2.6578296e-03,  2.2040114e-03,  3.3222167e-03,\n",
       "         3.2425704e-03, -4.6630697e-03,  5.6863163e-04,  1.5820221e-03,\n",
       "        -2.7095466e-03,  2.4742945e-03,  5.6082685e-04, -1.5839976e-03,\n",
       "         3.1859726e-03, -3.1347189e-03,  1.5992092e-03, -9.8144123e-04,\n",
       "         1.4406356e-03,  4.7025471e-03, -2.3970534e-03, -2.6333984e-03,\n",
       "        -4.7854413e-03, -3.0902349e-03, -5.2848429e-04, -3.6519894e-05,\n",
       "         1.9558552e-03, -1.8894932e-03,  4.5767725e-03, -5.4148100e-03,\n",
       "        -9.7400788e-04,  4.6041496e-03,  1.5524288e-03, -2.2775072e-03,\n",
       "         2.8487984e-03, -2.3918073e-03, -1.1381648e-03, -2.1543424e-03,\n",
       "        -8.7625475e-04,  4.4127442e-03,  3.8204547e-03, -2.5826921e-03,\n",
       "         1.9373123e-03,  3.2103043e-03,  4.7630938e-03,  1.1044990e-03,\n",
       "         4.8122918e-03,  6.5543834e-04, -2.6939851e-03,  3.9022972e-03,\n",
       "        -4.3527684e-03, -2.8251354e-03, -2.5714156e-03, -4.8162858e-03,\n",
       "         4.3086981e-04,  3.5808501e-03,  6.4478791e-04, -6.3282205e-06,\n",
       "        -9.9604332e-04,  2.0881922e-03, -1.0407341e-03,  4.1027949e-03,\n",
       "        -1.4314959e-03, -1.8262877e-03, -4.0733507e-03,  8.8522199e-04,\n",
       "         1.3080899e-03,  1.3593144e-03, -2.1957923e-03, -9.9043513e-04,\n",
       "         7.7627326e-04,  4.1879462e-03, -2.3756118e-04,  5.0776424e-03,\n",
       "         2.3418085e-03, -6.0179206e-03, -2.2296468e-03,  1.1161331e-03,\n",
       "        -4.0213750e-03, -9.9005026e-04,  2.1313687e-03, -1.2366010e-03,\n",
       "        -1.0428866e-03, -4.8416387e-04, -4.1474383e-03, -2.1836651e-03,\n",
       "        -3.4051607e-03, -2.1771591e-03,  4.0101893e-03,  1.8936915e-03,\n",
       "         4.3050316e-03,  1.7066717e-03, -4.7220103e-03,  2.2728667e-03,\n",
       "         1.6711343e-03,  5.8742003e-03,  2.8038113e-03, -3.9016698e-03,\n",
       "        -2.3150062e-03, -8.2725217e-04, -2.5029506e-03, -1.6718757e-03,\n",
       "         6.7894156e-03, -6.0813362e-03,  3.5285940e-03,  2.9294640e-03,\n",
       "         8.2050392e-04, -3.2135984e-05,  3.9320155e-03, -7.8282133e-04,\n",
       "         1.7207214e-03,  7.7681878e-04, -1.5590107e-03,  3.7278081e-03,\n",
       "         3.5353026e-03,  1.6370435e-03,  2.2154753e-03, -5.2124890e-04,\n",
       "        -5.8740942e-04, -1.7727641e-03, -3.2666256e-05, -6.1005820e-05,\n",
       "        -7.6889992e-04, -1.2222733e-03,  2.2196579e-03,  9.2693488e-05,\n",
       "         2.1978235e-03, -1.9501271e-03,  1.5043889e-03, -1.1569223e-03,\n",
       "         1.8184606e-03,  1.1038189e-03,  7.2519400e-04,  8.1470818e-04,\n",
       "         1.8656952e-05,  4.7012846e-04,  1.7003326e-03, -1.0404411e-03,\n",
       "        -1.4729092e-03,  1.6904769e-03, -1.5604439e-03,  4.5145154e-03,\n",
       "         1.3048360e-03,  5.5637921e-04, -7.2787865e-04, -1.6062816e-03,\n",
       "        -8.6696330e-04, -2.8850622e-03,  3.0061887e-03,  2.1204352e-05,\n",
       "         2.7581160e-03,  4.4270889e-03, -1.2277757e-03,  8.5751375e-04,\n",
       "        -9.6353854e-04,  6.2078546e-04, -3.2408821e-04, -3.6810484e-04,\n",
       "         6.0084695e-04,  2.3517627e-03, -7.0703728e-04,  2.7796917e-04,\n",
       "        -1.1787028e-03, -1.0071974e-04, -3.4443205e-03, -1.1227001e-03,\n",
       "        -1.9639316e-03,  2.4540005e-03,  1.2296119e-03,  1.4304586e-03,\n",
       "         5.4264977e-04,  7.9337705e-04, -1.1513493e-03,  5.7045842e-04,\n",
       "        -1.0141463e-03,  2.6091039e-03, -1.5755454e-03, -2.0286255e-03,\n",
       "        -3.5015303e-03,  1.0800394e-03,  1.1299130e-03,  1.0735811e-03,\n",
       "         2.1870593e-03,  3.4496313e-04, -1.5906687e-03, -5.0324900e-04,\n",
       "        -1.4091736e-03,  3.1055168e-03,  5.3531374e-05,  2.2549488e-04,\n",
       "         1.7581360e-03, -1.3759097e-03,  1.2950557e-03, -5.6041963e-04,\n",
       "         8.6081948e-04,  2.9657083e-04,  2.1788833e-04,  1.5818769e-03,\n",
       "        -2.0770978e-03, -1.2875641e-03, -1.6021437e-04,  1.1936130e-03,\n",
       "        -1.0037217e-03,  7.8095269e-04, -1.9352966e-03,  2.3615167e-03,\n",
       "        -6.3770736e-04,  1.5492004e-04, -1.6273094e-03, -1.1286610e-03,\n",
       "         3.6260797e-04, -5.2531599e-04,  1.6274700e-03,  2.9157700e-03,\n",
       "         6.1988301e-04,  8.2264468e-04, -7.7568291e-04,  5.8875722e-04,\n",
       "         5.0827721e-04,  3.7651887e-04, -1.1978371e-03,  1.6717240e-06,\n",
       "        -1.6315491e-05, -6.3413859e-04,  3.5929377e-04,  1.8686948e-03,\n",
       "        -3.8730998e-03, -4.8029638e-04, -2.5089334e-03, -1.4223303e-03,\n",
       "        -1.4738035e-03,  1.8565522e-03,  3.0159278e-04,  5.5378629e-04,\n",
       "        -9.5386052e-04,  5.3231977e-04, -2.8340146e-03,  5.8077212e-04,\n",
       "        -1.5112525e-03, -1.0732473e-03,  2.5074002e-03,  6.7134044e-04,\n",
       "        -3.0957323e-03, -9.6097885e-04, -1.9552580e-03, -3.9247132e-04,\n",
       "        -1.7140623e-03,  1.4987323e-03,  2.1223561e-03,  3.2953685e-03,\n",
       "         2.5447882e-03,  4.2585173e-04,  6.1234989e-04, -3.1079762e-06,\n",
       "         1.1566093e-03,  1.2528108e-03,  2.1696021e-04, -8.3165732e-04,\n",
       "        -2.9066505e-03,  3.3717132e-03, -2.1179989e-03,  1.0448664e-03,\n",
       "        -3.0864051e-03, -7.9078821e-04, -2.1114338e-03, -8.7911490e-04,\n",
       "         5.8610796e-04, -5.1296351e-04, -3.8122453e-04, -7.0608826e-04,\n",
       "        -1.7986904e-04,  1.3825102e-03,  1.6991304e-03, -1.3937037e-03,\n",
       "         1.5750106e-03, -1.7605097e-03, -7.1738497e-05,  1.5172334e-03,\n",
       "        -9.9265855e-04, -2.2564069e-03, -2.0988248e-03,  3.7133391e-03,\n",
       "         6.9237931e-04,  2.0921689e-03, -4.5054103e-04,  1.3791535e-03,\n",
       "         1.3425369e-03, -6.7217706e-04, -2.9046400e-04,  1.3558001e-03,\n",
       "         1.7610362e-03, -1.1533540e-03,  7.4249110e-05,  1.5884856e-04,\n",
       "        -1.1531562e-03, -4.4441363e-04,  2.5947844e-03, -1.4996389e-05,\n",
       "        -2.7701594e-03,  1.7732666e-03,  1.6463997e-03, -1.3614399e-03,\n",
       "         1.8643447e-03, -2.2385053e-03,  8.3813258e-04, -1.7549566e-04,\n",
       "        -4.2133126e-04,  1.3340745e-03, -2.8780836e-05, -1.1564794e-03,\n",
       "         1.1204502e-03, -1.4536690e-03, -1.3126200e-03, -2.8289692e-03,\n",
       "        -4.0112580e-03,  5.1345635e-04,  5.2777759e-04, -1.1824899e-03,\n",
       "        -2.9907771e-03, -2.3277886e-03, -1.8814724e-03,  3.6467647e-04,\n",
       "         1.9893767e-03, -1.6291988e-03,  2.6604247e-03, -1.3399220e-03,\n",
       "        -3.8742532e-03, -1.0411055e-03, -1.4544696e-03,  2.1210796e-04,\n",
       "         1.5362737e-03,  1.8394523e-04,  2.2567690e-03, -2.8019137e-04,\n",
       "         7.0487126e-04,  1.9412654e-03,  5.7952659e-04, -2.8474984e-04,\n",
       "         2.7675999e-03, -1.9352406e-03, -7.1408716e-04, -2.2671407e-04,\n",
       "        -1.4710589e-03, -4.4802536e-04, -2.9772706e-03, -5.6254445e-03,\n",
       "        -4.2001256e-03,  2.2735388e-05,  2.4187593e-03, -2.6863511e-03,\n",
       "         1.0395509e-03,  7.9211290e-04,  1.7952179e-03,  1.8692106e-03,\n",
       "        -2.0064779e-03, -1.5992130e-04, -5.6093815e-04, -2.7234154e-03,\n",
       "        -2.0270378e-03, -1.1045883e-03,  3.0278217e-03,  1.3133074e-04,\n",
       "         1.8167601e-04,  6.6522777e-04,  3.9841270e-04, -4.7157910e-03,\n",
       "        -1.3473758e-03, -1.5133605e-03, -1.7820400e-03,  2.0892660e-03,\n",
       "         2.4792948e-03, -2.8827228e-03, -3.3035870e-03,  8.3860348e-04,\n",
       "         5.9459417e-04,  1.9799829e-03,  1.0966372e-03, -1.2252440e-03,\n",
       "         5.3528394e-03, -4.8745709e-04, -2.1143686e-03,  2.0749480e-03,\n",
       "         7.0005225e-04,  2.6540188e-03,  2.2005779e-03, -2.0445699e-03,\n",
       "        -8.0303481e-04,  1.8049346e-03, -3.1465688e-03,  1.3991215e-03,\n",
       "         6.6609751e-04, -1.7858167e-03,  2.4979287e-03,  1.9317986e-03,\n",
       "         1.5422977e-03, -2.6136916e-03, -7.9292106e-05,  3.1616674e-03,\n",
       "         1.1515664e-03,  2.0542741e-03,  1.2931393e-03,  2.8201202e-03,\n",
       "        -1.7812239e-03,  2.4737364e-03, -3.3637788e-03, -8.3828642e-04,\n",
       "        -2.0927493e-03,  1.7277956e-03, -1.0519510e-03, -1.0589482e-03,\n",
       "         1.2669133e-03, -1.4892468e-03,  9.3702803e-04,  1.6191739e-03,\n",
       "        -1.3767362e-03, -1.5547443e-03,  2.5550562e-03,  9.0155192e-04],\n",
       "       dtype=float32),)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_vectors(new_model, dft_tagged)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99255140e-01, 7.44860348e-04]])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict_proba(X_test[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-674a2b4ed84f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     lambda r: TaggedDocument(words=tokenize_text(r['Text']), tags=[r.MH]), axis=1)\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mvec_for_learning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdft_tagged\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvec_for_learning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdft_tagged\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'new_model' is not defined"
     ]
    }
   ],
   "source": [
    "input_text ='counselling'\n",
    "\n",
    "dft_tagged = pd.DataFrame([[input_text, 0]], columns = ['Text', 'MH']).apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['Text']), tags=[r.MH]), axis=1)\n",
    "\n",
    "get_vectors(new_model, dft_tagged)[1]\n",
    "\n",
    "logreg.predict_proba(get_vectors(new_model, dft_tagged)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.59081039, 0.40918961]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text ='i am sad'\n",
    "\n",
    "dft_tagged = pd.DataFrame([[input_text, 0]], columns = ['Text', 'MH']).apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['Text']), tags=[r.MH]), axis=1)\n",
    "\n",
    "vec_for_learning(model_dbow, dft_tagged)[1]\n",
    "\n",
    "logreg.predict_proba(vec_for_learning(model_dbow, dft_tagged)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
